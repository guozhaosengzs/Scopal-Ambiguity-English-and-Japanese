---
title: "Analysis"
author: "Zhaosen Guo"
date: "7/10/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, comment=NA)
```

# Intro {#intro}

For the given psycholinguistics experiment data, I have generated this R Markdown file for easier access to the data, codes, and explanations. This file can also generate reports in html/pdf when pressing the "Knit" option in RStudio.  
(FYI, a R Markdown cheat sheet is included in the folder.)
  
Here are the required libraries:
```{r Libraries, warning=FALSE, message=FALSE}
library(tidyverse)
library(lme4)
library(lmerTest)
```
<br>

We will be running the following mixed-effect models with variables and parameters -

Language | Independent Variable (Fixed effect) |  Dependent Variable |  Random Effects   | Link            | Result |
:------: | :---------------------------------: | :-----------------: | :---------------: | :--------------:| :-----:|
English | sentence context (scope & negation) | sentence length (ms)| subjects & keywords| [jump](#model1) | |
Japanese | sentence context (scope & negation) | sentence length (ms)| subjects & keywords| [jump](#model2) | |
English | sentence context (scope & negation) | fundamental frequency (Hz)| subjects & keywords| [jump](#model3) | |
Japanese | sentence context (scope & negation) | fundamental frequency (Hz)| subjects & keywords| [jump](#model4) | ** |
English  | sentence context (scope & negation) | sentence length (ms)| subjects & keywords **w/out "wool"**| [jump](#model5) | |
Japanese  | sentence context (scope & negation) | sentence length (ms)| subjects & keywords **w/out "wool"**| [jump](#model6) | |
English  | sentence context (scope & negation) | fundamental frequency (Hz) | subjects & keywords **w/out "wool"**| [jump](#model7) | ** |
Japanese  | sentence context (scope & negation) | fundamental frequency (Hz) | subjects & keywords **w/out "wool"**| [jump](#model8) | ** |
English  | sentence context (scope & negation) | first formant (Hz) | subjects & keywords **w/out "wool"**| [jump](#model9) |  |
English  | sentence context (scope & negation) | second formant (Hz) | subjects & keywords **w/out "wool"**| [jump](#model10) |  |
English  | sentence context (scope & negation) | third formant (Hz) | subjects & keywords **w/out "wool"**| [jump](#model11) | ** |
Japanese  | sentence context (scope & negation) | first formant (Hz) | subjects & keywords **w/out "wool"**| [jump](#model12) | * |
Japanese  | sentence context (scope & negation) | second formant (Hz) | subjects & keywords **w/out "wool"**| [jump](#model13) | |
Japanese  | sentence context (scope & negation) | third formant (Hz) | subjects & keywords **w/out "wool"**| [jump](#model14) | |
English  | sentence context (scope & negation) | gesture length (ms) | subjects & keywords **w/out "wool"**| [jump](#model15) | * |
Japanese  | sentence context (scope & negation) | gesture length (ms) | subjects & keywords **w/out "wool"**| [jump](#model16) | * |
English  | sentence context (scope & negation) | last word length (ms) | subjects & keywords **w/out "wool"**| [jump](#model17) |  |
Japanese  | sentence context (scope & negation) | last word length (ms) | subjects & keywords **w/out "wool"**| [jump](#model18) |  |

# Models

### Context vs Sentence Length, English {#model1}
###### [back to top](#intro)

First, import the data set.
```{r message=FALSE, warning=FALSE}
data.SenLen.Eng <- read_csv("data/SentenceLengthEnglish.csv")
```

The code below shows that the class types of the data are not correct. 
```{r}
sapply(data.SenLen.Eng, class)
```
Change them from character class to factor class.
```{r}
col_target <- c("subject", "sentence", "context", "keyword")
data.SenLen.Eng[col_target] <- lapply(data.SenLen.Eng[col_target], as.factor)
```
  
Now the mixed-effect model:
```{r message=FALSE, warning=FALSE}
model.SenLen.Eng<- lmer(data = data.SenLen.Eng, 
                        sentence_length ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.SenLen.Eng)
```
<br>
From the last section of the "Fixed effects" above, we can see that non of the context level displayed statistical significance in influencing the sentence length. 

### Context vs Sentence Length, Japanese {#model2}
###### [back to top](#intro)

Import and process the data:

```{r message=FALSE, warning=FALSE}
data.SenLen.Jap <- read_csv("data/SentenceLengthJapanese.csv")
data.SenLen.Jap[col_target] <- lapply(data.SenLen.Jap[col_target], as.factor)
```

Model:

```{r message=FALSE, warning=FALSE}
model.SenLen.Jap <- lmer(data = data.SenLen.Jap, 
                        sentence_length ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.SenLen.Jap)
```
<br>

Similar to the English result, there's no significant correlation between sentence context and sentence length in Japanese.

### Context vs Fundamental Frequency (F0), English {#model3}
###### [back to top](#intro)
##### Model for the mean fundamental frequency during the sentence (meanF0):
```{r message=FALSE, warning=FALSE}
model.meanF0.Eng <- lmer(data = data.SenLen.Eng, 
                        meanF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.meanF0.Eng)
```
##### Model for the max fundamental frequency during the sentence (maxF0):
```{r message=FALSE, warning=FALSE}
model.maxF0.Eng <- lmer(data = data.SenLen.Eng, 
                        maxF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.maxF0.Eng)
```
<br>

For the models above, there's no significant correlation between sentence context and fundamental frequencies in English.

### Context vs Fundamental Frequency(F0), Japanese {#model4}
###### [back to top](#intro)
##### Model for the mean fundamental frequency during the sentence (meanF0):
```{r message=FALSE, warning=FALSE}
model.meanF0.Jap <- lmer(data = data.SenLen.Jap, 
                        meanF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.meanF0.Jap)
```
For Japanese, the mean fundamental frequency in the sentence, when using "most/many > not" and "not > most/many" to compare with the baseline of "all > not", shows positive correlation. That means, when using the two contexts in the sentence, test subjects on average increase the F0 by respectively 4 or 6 Hz. 


##### Model for the max fundamental frequency during the sentence (maxF0):
```{r message=FALSE, warning=FALSE}
model.maxF0.Jap <- lmer(data = data.SenLen.Jap, 
                        maxF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.maxF0.Jap)
```
<br>
For the models above, there's no significant correlation between sentence context and max fundamental frequencies in Japanese


### Testing Models without "wool"
###### [back to top](#intro)
We realized that the sentences with "wool" in the experiment carry out different emotional suggestions, which make them standout among other sentences used. As a result, here are some models ran previously, with the modification of removing the entries with "wool" as *keyword*, which is part of the random effects. 

#### Context vs Sentence Length, English, w/out "wool" {#model5}
Remove the rows with "wool" as keywords.
```{r}
test.data.SenLen.Eng <- subset(data.SenLen.Eng, keyword != "wool")
nrow(data.SenLen.Eng) - nrow(test.data.SenLen.Eng)
```
Hence, 50 rows of the English data were removed. 

```{r message=FALSE, warning=FALSE}
model1.test.SenLen.Eng<- lmer(data = test.data.SenLen.Eng, 
                        sentence_length ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model1.test.SenLen.Eng)
```
<br>
Compared to the previous [model](#model1), aside from changing the "random effect" part of the report, the removal of one category of the random effects actually increased the residuals and std. error of the model, which means the differences sentiments between the "wool" sentences and other keywords was not big enough to cause a fundamental change in the results.  

#### Context vs Sentence Length, Japanese, w/out "wool" {#model6}
Remove the rows with "wool" as keywords.
```{r message=FALSE, warning=FALSE}
test.data.SenLen.Jap <- subset(data.SenLen.Jap, keyword != "wool")
nrow(data.SenLen.Jap) - nrow(test.data.SenLen.Jap)
```
Hence, 40 rows of the Japanese data were removed. 

```{r message=FALSE, warning=FALSE}
model1.test.SenLen.Jap<- lmer(data = test.data.SenLen.Jap, 
                        sentence_length ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model1.test.SenLen.Jap)
```
Similar to what was shown above, when compared to the previous [model](#model2), the results showed no significance. 

#### Context vs Fundamental Frequency, English, w/out "wool" {#model7}
max F0 - 
```{r message=FALSE, warning=FALSE}
model2.test.SenLen.Eng<- lmer(data = test.data.SenLen.Eng, 
                        maxF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model2.test.SenLen.Eng)
```
<br>
The max F0's result showed no significance between the maximum fundamental frequency and different sentence contexts. 

mean F0 - 
```{r message=FALSE, warning=FALSE}
model3.test.SenLen.Eng<- lmer(data = test.data.SenLen.Eng, 
                        meanF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model3.test.SenLen.Eng)
```
<br>
Here is a interesting result, because when "wool" is removed from the random effects, the new result is extremely different from the previous [result](#model3) that used the data with "wool." The new outcome showed that when comparing with the benchmark of "all > not", both "most/many > not" and "not > most/many" as a statistically significant increase in the mean fundamental frequency throughout the sentence, meaning that when the subjects were using those two context, their average F0 has the respective 8.8 Hz or 12.2 HZ increase. 

#### Context vs Fundamental Frequency, Japanese, w/out "wool" {#model8}
The Japanese dataset, max F0 - 
```{r message=FALSE, warning=FALSE}
model2.test.SenLen.Jap<- lmer(data = test.data.SenLen.Jap, 
                        maxF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model2.test.SenLen.Jap)
```
<br>
The max F0's result showed no significance between the maximum fundamental frequency and different sentence contexts. 

mean F0 - 
```{r message=FALSE, warning=FALSE}
model3.test.SenLen.Jap<- lmer(data = test.data.SenLen.Jap, 
                        meanF0 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model3.test.SenLen.Jap)
```
<br>
This is a slightly different case, since the original [model](#model4) already showed significance of using contexts would affect the mean fundamental frequency of the sentence. In the new dataset that does not include 'wool", the "most/many > not" and "not > most/many" are still the factors that are significant, and teh removal of one variable level in the random effect increase their significance (the corresponding P value decreased).
<br>

From our tests above, there are evidence that the model would be less confused when "wool" is not included in the data, therefore, in the models below on other formants of the speech, the models will use the updated version. 
### Context vs First Formant (F1), English {#model9}
###### [back to top](#intro)
```{r message=FALSE, warning=FALSE}
model.f1.Eng<- lmer(data = test.data.SenLen.Eng, 
                        F1 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.f1.Eng)
```
<br>
The model showed no correlation between sentence context and F1 frequency. 

### Context vs Second Formant (F2), English {#model10}
###### [back to top](#intro)
```{r message=FALSE, warning=FALSE}
model.f2.Eng<- lmer(data = test.data.SenLen.Eng, 
                        F2 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.f2.Eng)
```
<br>
The model showed no correlation between sentence context and F2 frequency. 


### Context vs third Formant (F3), English {#model11}
###### [back to top](#intro)
```{r message=FALSE, warning=FALSE}
model.f3.Eng<- lmer(data = test.data.SenLen.Eng, 
                        F3 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.f3.Eng)
```
<br>

The model showed that the context exhibit significant difference in the third formant when the subjects were speaking in English using "most/many > not" and "not > most/many", and their third formant frequency are lower (202 Hz and 138 HZ respectively) compared with speaking in "all > not".

### Context vs First Formant (F1), Japanese {#model12}
###### [back to top](#intro)
```{r message=FALSE, warning=FALSE}
model.f1.Jap<- lmer(data = test.data.SenLen.Jap, 
                        F1 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.f1.Jap)
```
<br>
The model showed that only one of the context "not > most/many" has a correlation to the decrease of 157 Hz in the first formant compared with the F1 frequency in the context of "all > not", when the subject is speaking Japanese.

### Context vs Second Formant (F2), Japanese {#model13}
###### [back to top](#intro)
```{r message=FALSE, warning=FALSE}
model.f2.Jap<- lmer(data = test.data.SenLen.Jap, 
                        F2 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.f2.Jap)
```
<br>
The model showed no correlation between sentence context and F2 frequency. 


### Context vs third Formant (F3), Japanese {#model14}
###### [back to top](#intro)
```{r message=FALSE, warning=FALSE}
model.f3.Jap<- lmer(data = test.data.SenLen.Jap, 
                        F3 ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.f3.Jap)
```
<br>

The model showed no correlation between sentence context and F3 frequency. 


### Context vs Gesture Length, English {#model15}
###### [back to top](#intro)
Import data, remove "wool" variable, and factor the levels .
```{r message=FALSE}
data.GesLen.Eng <- read_csv("data/GestureLengthEnglish.csv")
data.GesLen.Eng<- subset(data.GesLen.Eng, keyword != "wool")
col_factor <- c("subject", "keyword", "context")
data.GesLen.Eng[col_factor] <- lapply(data.GesLen.Eng[col_factor], as.factor)
```
Run the model.
```{r message=FALSE, warning=FALSE}
model.GesLen.Eng<- lmer(data = data.GesLen.Eng, 
                        duration ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.GesLen.Eng)
```
<br>
Contrary to the results shown so far, when it comes to the gestures by the English-speaking subjects, changing context "all > not" to "not > all" would decrease the gesture duration by around 354 ms, with a rather good significance. 


### Context vs Gesture Length, Japanese {#model16}
###### [back to top](#intro)
Import data, and factor the variable levels.
```{r message=FALSE, warning=FALSE}
data.GesLen.Jap <- read_csv("data/GestureLengthJapanese.csv")
data.GesLen.Jap<- subset(data.GesLen.Jap, keyword != "wool")
data.GesLen.Jap[col_factor] <- lapply(data.GesLen.Jap[col_factor], as.factor)
```
Run the model.
```{r message=FALSE, warning=FALSE}
model.GesLen.Jap<- lmer(data = data.GesLen.Jap,
                        duration ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.GesLen.Jap)
```
<br>
With the Japanese-speaking subjects, the significant correlation in the model is on the "most/many > not", and when compared with baseline, the gesture duration is around 114 ms. 


### Context vs Gesture Length, English {#model17}
###### [back to top](#intro)
Import data, remove "wool" variable, and factor the levels .
```{r message=FALSE}
data.LastLen.Eng <- read_csv("data/LastLenEng.csv")
data.LastLen.Eng<- subset(data.LastLen.Eng, keyword != "wool")
data.LastLen.Eng[col_factor] <- lapply(data.LastLen.Eng[col_factor], as.factor)
```
Run the model.
```{r message=FALSE, warning=FALSE}
model.LastLen.Eng<- lmer(data = data.LastLen.Eng, 
                        last_word_len ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.LastLen.Eng)
```
<br>
The model found no statistical significant correlation between the duration of the last word in the sentence and the context of sentence, with English-speaking subjects.


### Context vs Gesture Length, Japanese {#model18}
###### [back to top](#intro)
Import data, and factor the variable levels.
```{r message=FALSE, warning=FALSE}
data.LastLen.Jap <- read_csv("data/LastLenJap.csv")
data.LastLen.Jap <- subset(data.LastLen.Jap, keyword != "wool")
data.LastLen.Jap[col_factor] <- lapply(data.LastLen.Jap[col_factor], as.factor)
```
Run the model.
```{r message=FALSE, warning=FALSE}
model.LastLen.Jap<- lmer(data = data.LastLen.Jap,
                        last_word_len ~ context + 
                          (1 + context||keyword) + 
                          (1 + context||subject), REML = FALSE, 
                        control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(model.LastLen.Jap)
```
<br>
The model found no statistical significant correlation between the duration of the last word in the sentence and the context of sentence, with Japanese-speaking subjects.

###### [back to top](#intro)